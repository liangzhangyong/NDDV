{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(BASE_DIR)\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Opendataval\n",
    "from dataval.dataloader import Register, DataFetcher, mix_labels, add_gauss_noise\n",
    "from dataval.datavaluation import NDDV\n",
    "\n",
    "from dataval.experiment import ExperimentMediator\n",
    "\n",
    "from dataval.experiment import ExperimentMediator\n",
    "\n",
    "from dataval.model.api import ClassifierSkLearnWrapper\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from dataval.model.logistic_regression import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters\n",
    "dataset_name = \"random_dataset\"\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = {'noise_rate': noise_rate}\n",
    "max_epoch = 5\n",
    "batch_size = 1000\n",
    "lr = 0.01\n",
    "random_state = 42\n",
    "train_kwargs = {\"epochs\": max_epoch, \"batch_size\": batch_size, \"lr\": lr}\n",
    "# model_name = \"classifiermlp\"   # \"sklogreg\"\n",
    "model_name = \"LogisticRegression\"\n",
    "metric_name = \"accuracy\"\n",
    "cache_dir = \"../data_files/\"\n",
    "add_noise = mix_labels\n",
    "noise_type = \"mix_labels\"\n",
    "device = 'cpu'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= np.random.normal(size=(2000000, 500)), np.random.choice([0,1], size=2000000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 1000000, 100000, 300000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5006666779518127\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(20000, 5)), np.random.choice([0,1], size=20000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 10000, 1000, 3000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:00:10.777498\n",
      "CPU times: user 2min 23s, sys: 1.06 s, total: 2min 24s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e4,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5096666812896729\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(20000, 50)), np.random.choice([0,1], size=20000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 10000, 1000, 3000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:00:11.943145\n",
      "CPU times: user 2min 47s, sys: 2.92 s, total: 2min 50s\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e4,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.518666684627533\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(20000, 500)), np.random.choice([0,1], size=20000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 10000, 1000, 3000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:18<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:00:18.203429\n",
      "CPU times: user 3min 55s, sys: 31 s, total: 4min 26s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.499099999666214\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(80000, 5)), np.random.choice([0,1], size=80000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 50000, 5000, 10000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:49<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:00:50.131060\n",
      "CPU times: user 11min 19s, sys: 4.4 s, total: 11min 23s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e4,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5013999938964844\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(80000, 50)), np.random.choice([0,1], size=80000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 50000, 5000, 10000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:59<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:01:00.312658\n",
      "CPU times: user 14min 10s, sys: 18 s, total: 14min 28s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e4,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.4999000132083893\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(80000, 500)), np.random.choice([0,1], size=80000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 50000, 5000, 10000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:27<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:01:27.779662\n",
      "CPU times: user 18min 30s, sys: 2min 50s, total: 21min 21s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.49363332986831665\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(200000, 1)), np.random.choice([0,1], size=200000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 100000, 10000, 30000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:07<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDDV(max_epochs=50, base_model=LogisticRegression, batch_size=1000, device=cpu): 0:02:08.264199\n",
      "CPU times: user 26min 21s, sys: 1min 4s, total: 27min 25s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.4935666620731354\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(200000, 50)), np.random.choice([0,1], size=200000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 100000, 10000, 30000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDSV(mfg_epochs=50, base_model=LogisticRegression, meta_interval=10, mfg_batch_size=1000, device=cuda): 0:01:40.923309\n",
      "CPU times: user 13min 28s, sys: 2.91 s, total: 13min 31s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e5,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.4993000030517578\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(200000, 500)), np.random.choice([0,1], size=200000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 100000, 10000, 30000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDSV(mfg_epochs=50, base_model=LogisticRegression, meta_interval=10, mfg_batch_size=1000, device=cuda): 0:01:49.100712\n",
      "CPU times: user 14min 29s, sys: 6.53 s, total: 14min 35s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5000200271606445\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(800000, 5)), np.random.choice([0,1], size=800000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 500000, 50000, 100000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:28<00:00, 10.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDSV(mfg_epochs=50, base_model=LogisticRegression, meta_interval=10, mfg_batch_size=1000, device=cuda): 0:08:30.125019\n",
      "CPU times: user 8min 40s, sys: 7.12 s, total: 8min 47s\n",
      "Wall time: 8min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5035300254821777\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(800000, 50)), np.random.choice([0,1], size=800000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 500000, 50000, 100000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:27<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDSV(mfg_epochs=50, base_model=LogisticRegression, meta_interval=10, mfg_batch_size=1000, device=cuda): 0:08:28.708342\n",
      "CPU times: user 1h 8min 6s, sys: 14.8 s, total: 1h 8min 21s\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5e5,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.501230001449585\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(800000, 500)), np.random.choice([0,1], size=800000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 500000, 50000, 100000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [05:45<07:20, 15.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 39s, sys: 19.8 s, total: 30min 59s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.5005733370780945\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(2000000, 5)), np.random.choice([0,1], size=2000000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 1000000, 100000, 300000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [17:09<00:00, 20.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time NDSV(mfg_epochs=50, base_model=LogisticRegression, meta_interval=10, mfg_batch_size=1000, device=cuda): 0:17:12.629810\n",
      "CPU times: user 17min 14s, sys: 16.7 s, total: 17min 31s\n",
      "Wall time: 17min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e6,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.4998700022697449\n"
     ]
    }
   ],
   "source": [
    "X, y= np.random.normal(size=(2000000, 50)), np.random.choice([0,1], size=2000000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 1000000, 100000, 300000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [15:37<01:44, 20.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 5min 39s, sys: 34.5 s, total: 2h 6min 13s\n",
      "Wall time: 15min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e6,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= np.random.normal(size=(2000000, 500)), np.random.choice([0,1], size=2000000)\n",
    "Register(dataset_name=dataset_name, one_hot=True).from_data(X, y)\n",
    "train_count, valid_count, test_count, meta_count = 1000000, 100000, 300000, 1000\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=cache_dir,  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    meta_count=meta_count,\n",
    "    add_noise=add_noise, \n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    random_state = random_state,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")\n",
    "\n",
    "data_evaluators = [NDDV(max_epochs=50, base_model=model_name,batch_size=batch_size,device=device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [03:56<15:46, 23.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 29s, sys: 24.4 s, total: 29min 54s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
